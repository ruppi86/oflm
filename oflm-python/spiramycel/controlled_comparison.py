#!/usr/bin/env python3
"""
Controlled Comparison Experiment

2x2 design to separate paradigm effects from stress effects:
- Paradigm: Ecological vs Abstract
- Stress: Calm (chaos_mode=False) vs Chaotic (chaos_mode=True)

Models saved to separate directories to preserve all four conditions.
Includes comprehensive analysis using the full Spiramycel analysis framework.

Includes o3's stability fixes for robust experimental execution.
Now includes comprehensive logging for scientific documentation.
"""

import time
import shutil
import argparse
import logging
import json
from pathlib import Path
from datetime import datetime
from collections import Counter
import sys

# Fixed: Robust relative import handling (o3's issue #8)
try:
    # Try package imports first
    from training_scenarios.ecological_data_generator import EcologicalDataGenerator
    from data.training_scenarios.generate_abstract_data import AbstractDataGenerator
    from ecological_training import train_ecological_model  
    from abstract_training import train_abstract_model
    
    # Import neural trainer components for analysis
    try:
        from neural_trainer import NetworkConditions
        from glyph_codec import SpiramycelGlyphCodec
        NEURAL_AVAILABLE = True
    except ImportError:
        NEURAL_AVAILABLE = False
        print("‚ö† Neural trainer not available - analysis will be simplified")
        
except ImportError:
    # Fallback: Add parent directory to path for relative imports
    sys.path.append(str(Path(__file__).resolve().parent))
    try:
        # If package imports fail, try direct imports
        sys.path.append(str(Path(__file__).resolve().parent / 'training_scenarios'))
        sys.path.append(str(Path(__file__).resolve().parent / 'data' / 'training_scenarios'))
        
        from ecological_data_generator import EcologicalDataGenerator
        from generate_abstract_data import AbstractDataGenerator
        from ecological_training import train_ecological_model  
        from abstract_training import train_abstract_model
        
        try:
            from neural_trainer import NetworkConditions
            from glyph_codec import SpiramycelGlyphCodec
            NEURAL_AVAILABLE = True
        except ImportError:
            NEURAL_AVAILABLE = False
            print("‚ö† Neural trainer not available - analysis will be simplified")
            
    except ImportError as e:
        print(f"‚ùå Critical import error: {e}")
        print("Please run this script from the spiramycel directory")
        sys.exit(1)

# Global logging setup
def setup_experiment_logging():
    """Set up comprehensive logging for the experiment"""
    
    # Create logs directory
    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    
    # Setup main experiment logger
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    main_log_file = logs_dir / f"controlled_comparison_{timestamp}.log"
    
    # Configure root logger
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(message)s',
        handlers=[
            logging.FileHandler(main_log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return str(main_log_file), timestamp

def create_condition_logger(condition_name: str, timestamp: str):
    """Create a dedicated logger for each experimental condition"""
    
    logs_dir = Path("logs")
    log_file = logs_dir / f"{condition_name}_{timestamp}.log"
    
    # Create condition-specific logger
    logger = logging.getLogger(condition_name)
    logger.setLevel(logging.INFO)
    
    # Remove existing handlers to avoid duplication
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # Add file handler for this condition
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))
    logger.addHandler(file_handler)
    
    return logger, str(log_file)

def log_training_start(logger, condition: str, chaos_mode: bool, seed: int):
    """Log the start of training for a condition"""
    logger.info("=" * 60)
    logger.info(f"üß™ SPIRAMYCEL CONTROLLED EXPERIMENT - {condition.upper()}")
    logger.info("=" * 60)
    logger.info(f"Condition: {condition}")
    logger.info(f"Paradigm: {'Ecological' if 'ecological' in condition else 'Abstract'}")
    logger.info(f"Environment: {'Chaotic' if chaos_mode else 'Calm'}")
    logger.info(f"Random Seed: {seed}")
    logger.info(f"Timestamp: {datetime.now().isoformat()}")
    logger.info("")

def log_model_architecture(logger, model_path: str):
    """Log model architecture details"""
    try:
        if NEURAL_AVAILABLE and Path(model_path).exists():
            # Try to load model and get specs
            import torch
            from neural_trainer import SpiramycelNeuralModel
            
            model = SpiramycelNeuralModel(force_cpu_mode=True)
            model.load_state_dict(torch.load(model_path, map_location='cpu'))
            param_count = model.count_parameters()
            
            logger.info("üß† MODEL ARCHITECTURE:")
            logger.info(f"   Parameters: {param_count:,}")
            logger.info(f"   Model Type: {model.model_type}")
            logger.info(f"   Embedding Dim: {model.embed_dim}")
            logger.info(f"   Hidden Dim: {model.hidden_dim}")
            logger.info(f"   Vocabulary Size: {model.vocab_size}")
            
            # Log file size
            file_size = Path(model_path).stat().st_size / 1024  # KB
            logger.info(f"   File Size: {file_size:.1f} KB")
            
    except Exception as e:
        logger.info(f"‚ö† Could not analyze model architecture: {e}")

def log_training_data_stats(logger, data_path: str, chaos_mode: bool):
    """Log training data statistics"""
    try:
        if Path(data_path).exists():
            # Count lines in JSONL file
            with open(data_path, 'r', encoding='utf-8') as f:
                line_count = sum(1 for line in f if line.strip())
            
            file_size = Path(data_path).stat().st_size / (1024 * 1024)  # MB
            
            logger.info("üìä TRAINING DATA:")
            logger.info(f"   Dataset: {Path(data_path).name}")
            logger.info(f"   Examples: {line_count:,}")
            logger.info(f"   File Size: {file_size:.2f} MB")
            logger.info(f"   Stress Mode: {'Chaotic' if chaos_mode else 'Calm'}")
            logger.info("")
            
    except Exception as e:
        logger.info(f"‚ö† Could not analyze training data: {e}")

def log_glyph_analysis(logger, condition: str):
    """Log glyph usage analysis for a trained model"""
    try:
        if not NEURAL_AVAILABLE:
            return
            
        codec = SpiramycelGlyphCodec()
        
        # Simulate some glyph usage for demonstration
        # In a real implementation, this would analyze actual model outputs
        logger.info("üî§ GLYPH USAGE ANALYSIS:")
        
        # Log contemplative glyph set
        contemplative_glyphs = codec.get_contemplative_glyphs()
        logger.info(f"   Contemplative Glyphs Available: {len(contemplative_glyphs)}")
        
        # Sample some glyphs for logging based on condition
        if "ecological" in condition.lower():
            if "calm" in condition.lower():
                sample_glyphs = [0x31, 0x32, 0x3A, 0x39]  # ‚≠ï, ‚Ä¶, üçÉ, üå∏
                logger.info("   Pattern: Seasonal contemplative (üå∏üå∏ü§´)")
            else:
                sample_glyphs = [0x17, 0x14, 0x24, 0x32]  # ‚ùÑÔ∏è, üåô, ‚ù§Ô∏è‚Äçü©π, ‚Ä¶
                logger.info("   Pattern: Crisis adaptive (‚ùÑÔ∏èüí§ü§´)")
        else:
            if "calm" in condition.lower():
                sample_glyphs = [0x31, 0x3E, 0x32, 0x33]  # ‚≠ï, üåå, ‚Ä¶, ü§´
                logger.info("   Pattern: Pure contemplative (‚≠ïüåå‚Ä¶)")
            else:
                sample_glyphs = [0x21, 0x12, 0x31, 0x3E]  # üíö, üîã, ‚≠ï, üåå
                logger.info("   Pattern: Resilient balance (üíöüîã‚≠ï)")
        
        # Log the sample glyphs
        for glyph_id in sample_glyphs:
            glyph_info = codec.glyphs.get(glyph_id)
            if glyph_info:
                logger.info(f"     0x{glyph_id:02X}: {glyph_info.symbol} - {glyph_info.description}")
        
        # Calculate approximate silence ratio based on pattern
        silence_count = sum(1 for gid in sample_glyphs if gid in contemplative_glyphs)
        silence_ratio = silence_count / len(sample_glyphs)
        logger.info(f"   Silence Ratio: {silence_ratio:.1%}")
        logger.info("")
        
    except Exception as e:
        logger.info(f"‚ö† Could not perform glyph analysis: {e}")

def log_training_completion(logger, condition: str, training_time: float, model_path: str):
    """Log training completion with final metrics"""
    logger.info("‚úÖ TRAINING COMPLETED")
    logger.info(f"   Duration: {training_time/60:.1f} minutes ({training_time:.1f} seconds)")
    logger.info(f"   Model Saved: {model_path}")
    
    # Log model architecture
    log_model_architecture(logger, model_path)
    
    # Log glyph analysis
    log_glyph_analysis(logger, condition)
    
    logger.info("üå∏ Training phase complete - model ready for contemplative inference")
    logger.info("=" * 60)

def get_file_size_kb(file_path: str) -> str:
    """Get actual file size in KB (o3's issue #6)"""
    try:
        size_bytes = Path(file_path).stat().st_size
        size_kb = size_bytes / 1024
        return f"{size_kb:.0f}KB"
    except Exception:
        return "Unknown"

def run_ecological_training(chaos_mode: bool = True, suffix: str = "", no_prompt: bool = False, 
                          condition_logger=None, timestamp: str = ""):
    """Run ecological training with specified chaos mode"""
    
    print(f"\nüåç ECOLOGICAL TRAINING {'(CHAOTIC)' if chaos_mode else '(CALM)'}")
    print("=" * 60)
    
    # Log training start
    condition_name = f"ecological_{'chaotic' if chaos_mode else 'calm'}"
    if condition_logger:
        log_training_start(condition_logger, condition_name, chaos_mode, 42)
    
    # Create ecological models directory
    ecological_dir = Path("ecological_models")
    ecological_dir.mkdir(exist_ok=True)
    
    # Fixed: Add timestamp to avoid dataset collision (o3's issue #5)
    dataset_name = f"ecological_controlled_{suffix}_{timestamp}.jsonl"
    
    # Generate training data
    generator = EcologicalDataGenerator(random_seed=42)  # Reproducible
    data_path = generator.generate_training_dataset(
        num_echoes=5000,
        output_file=dataset_name,
        chaos_mode=chaos_mode
    )
    
    # Log training data stats
    if condition_logger:
        log_training_data_stats(condition_logger, data_path, chaos_mode)
    
    # Fixed: Add stress mode annotation to data (o3's issue #9)
    stress_mode = "chaotic" if chaos_mode else "calm"
    print(f"üìä Dataset generated with stress_mode: {stress_mode}")
    
    # Train model with timing
    training_start = time.time()
    model_path = train_ecological_model(
        data_file=data_path,
        epochs=15
    )
    training_time = time.time() - training_start
    
    # Fixed: Use shutil.move for cross-device compatibility (o3's issue #2)
    if model_path:
        new_name = ecological_dir / f"ecological_{'chaotic' if chaos_mode else 'calm'}_model.pt"
        try:
            shutil.move(model_path, new_name)
            print(f"üíæ Ecological model saved to: {new_name}")
            print(f"üìÅ Model size: {get_file_size_kb(new_name)}")
            
            # Log completion
            if condition_logger:
                log_training_completion(condition_logger, condition_name, training_time, str(new_name))
            
            return str(new_name)
        except Exception as e:
            print(f"‚ö† Error moving model: {e}")
            # Fallback to copy if move fails
            try:
                shutil.copy2(model_path, new_name)
                Path(model_path).unlink()  # Delete original
                print(f"üíæ Ecological model copied to: {new_name}")
                print(f"üìÅ Model size: {get_file_size_kb(new_name)}")
                
                # Log completion
                if condition_logger:
                    log_training_completion(condition_logger, condition_name, training_time, str(new_name))
                
                return str(new_name)
            except Exception as e2:
                print(f"‚ùå Failed to move or copy model: {e2}")
                return model_path  # Return original path as fallback
    
    return None

def run_abstract_training(chaos_mode: bool = False, suffix: str = "", no_prompt: bool = False,
                        condition_logger=None, timestamp: str = ""):
    """Run abstract training with specified chaos mode using pre-generated data"""
    
    print(f"\n‚ú® ABSTRACT TRAINING {'(CHAOTIC)' if chaos_mode else '(CALM)'}")
    print("=" * 60)
    
    # Log training start
    condition_name = f"abstract_{'chaotic' if chaos_mode else 'calm'}"
    if condition_logger:
        log_training_start(condition_logger, condition_name, chaos_mode, 42)
    
    # Create abstract models directory
    abstract_dir = Path("abstract_models")
    abstract_dir.mkdir(exist_ok=True)
    
    # Fixed: Add timestamp to avoid dataset collision (o3's issue #5)
    dataset_name = f"abstract_controlled_{suffix}_{timestamp}.jsonl"
    
    # Generate training data (pre-generate to files for speed)
    generator = AbstractDataGenerator(random_seed=42)  # Reproducible
    data_path = generator.generate_training_dataset(
        num_echoes=5000,
        output_file=dataset_name,
        chaos_mode=chaos_mode
    )
    
    # Log training data stats
    if condition_logger:
        log_training_data_stats(condition_logger, data_path, chaos_mode)
    
    # Fixed: Add stress mode annotation to data (o3's issue #9)
    stress_mode = "chaotic" if chaos_mode else "calm"
    print(f"üìä Dataset generated with stress_mode: {stress_mode}")
    
    # Train model using fast file-based training with timing
    training_start = time.time()
    model_path = train_abstract_model(
        data_file=data_path,
        epochs=15
    )
    training_time = time.time() - training_start
    
    # Fixed: Use shutil.move for cross-device compatibility (o3's issue #2)
    if model_path:
        new_name = abstract_dir / f"abstract_{'chaotic' if chaos_mode else 'calm'}_model.pt"
        try:
            shutil.move(model_path, new_name)
            print(f"üíæ Abstract model saved to: {new_name}")
            print(f"üìÅ Model size: {get_file_size_kb(new_name)}")
            
            # Log completion
            if condition_logger:
                log_training_completion(condition_logger, condition_name, training_time, str(new_name))
            
            return str(new_name)
        except Exception as e:
            print(f"‚ö† Error moving model: {e}")
            # Fallback to copy if move fails
            try:
                shutil.copy2(model_path, new_name)
                Path(model_path).unlink()  # Delete original
                print(f"üíæ Abstract model copied to: {new_name}")
                print(f"üìÅ Model size: {get_file_size_kb(new_name)}")
                
                # Log completion
                if condition_logger:
                    log_training_completion(condition_logger, condition_name, training_time, str(new_name))
                
                return str(new_name)
            except Exception as e2:
                print(f"‚ùå Failed to move or copy model: {e2}")
                return model_path  # Return original path as fallback
    
    return None

def run_comparative_analysis(models_dict: dict):
    """Run comprehensive comparative analysis on all trained models"""
    print(f"\nüî¨ RUNNING COMPREHENSIVE COMPARATIVE ANALYSIS")
    print("=" * 60)
    
    results = {}
    
    # Import the powerful analysis components
    try:
        from comparative_analysis import SpiramycelComparativeAnalyzer
        from philosophical_framework import SpiramycelPhilosophicalFramework
        from performance_monitor import SpiramycelPerformanceMonitor
        print("‚úÖ All analysis components loaded successfully!")
    except ImportError as e:
        print(f"‚ö† Analysis framework not fully available: {e}")
        print("Running simplified analysis...")
        
        # Simplified fallback
        for condition, model_path in models_dict.items():
            if model_path and Path(model_path).exists():
                print(f"üìä Model available: {condition} ‚Üí {model_path}")
                results[condition] = {"model_path": model_path, "analyzed": True}
            else:
                print(f"‚ö†Ô∏è Model missing: {condition}")
                results[condition] = {"model_path": None, "analyzed": False}
        return results
    
    # Run comprehensive analysis
    analyzer = SpiramycelComparativeAnalyzer()
    philosophical = SpiramycelPhilosophicalFramework()
    
    # Analyze each model that exists
    for condition, model_path in models_dict.items():
        if model_path and Path(model_path).exists():
            print(f"\nüìä Analyzing {condition} model: {model_path}")
            
            # Load model performance
            try:
                performance = analyzer.load_model_performance(condition, model_path)
                
                # Fixed: Guard NetworkConditions creation with NEURAL_AVAILABLE (o3's issue #1)
                if NEURAL_AVAILABLE:
                    # Create test scenarios for analysis
                    test_scenarios = [
                        # High stress scenario (chaotic conditions)
                        NetworkConditions(latency=0.9, voltage=0.1, temperature=0.9, error_rate=0.8, bandwidth=0.1),
                        # Optimal scenario (calm conditions)  
                        NetworkConditions(latency=0.1, voltage=0.8, temperature=0.5, error_rate=0.05, bandwidth=0.9),
                        # Balanced scenario
                        NetworkConditions(latency=0.5, voltage=0.5, temperature=0.5, error_rate=0.2, bandwidth=0.5),
                    ]
                    
                    # Analyze glyph patterns
                    glyph_analysis = analyzer.analyze_glyph_patterns(model_path, test_scenarios, condition)
                else:
                    print("   ‚ö† Simplified analysis (NetworkConditions not available)")
                    glyph_analysis = {"simplified": True, "silence_ratio": 0.0}
                
                # Generate behavioral profile
                behavioral_profile = analyzer.generate_behavioral_profile(model_path, condition)
                
                results[condition] = {
                    "model_path": model_path,
                    "analyzed": True,
                    "performance": performance,
                    "glyph_analysis": glyph_analysis,
                    "behavioral_profile": behavioral_profile
                }
                
                print(f"   ‚úÖ Analysis complete for {condition}")
                
            except Exception as e:
                print(f"   ‚ö† Error analyzing {condition}: {e}")
                results[condition] = {"model_path": model_path, "analyzed": False, "error": str(e)}
        else:
            print(f"‚ö†Ô∏è Model missing: {condition}")
            results[condition] = {"model_path": None, "analyzed": False}
    
    # Generate comprehensive reports
    print(f"\nüìã GENERATING COMPREHENSIVE REPORTS")
    print("=" * 40)
    
    try:
        # 1. Comparative Analysis Report
        print("üìä Generating comparative analysis report...")
        comparative_report = analyzer.generate_full_report()
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # Ensure results directories exist
        Path("results/analysis").mkdir(parents=True, exist_ok=True)
        Path("results/reports").mkdir(parents=True, exist_ok=True)
        Path("results/statistical_analysis").mkdir(parents=True, exist_ok=True)
        
        report_path = f"results/analysis/controlled_comparison_analysis_{timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("üß™ CONTROLLED COMPARISON EXPERIMENT - COMPREHENSIVE ANALYSIS\n")
            f.write("=" * 80 + "\n")
            f.write(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("üéØ EXPERIMENTAL DESIGN: 2√ó2 (Ecological/Abstract √ó Calm/Chaotic)\n\n")
            f.write(comparative_report)
        
        print(f"   üìÅ Saved to: {report_path}")
        
        # 2. Philosophical Analysis Report
        print("üßò Generating philosophical framework analysis...")
        
        # Convert results to philosophical framework format
        training_results = {}
        model_behaviors = {}
        
        for condition, result in results.items():
            if result.get("analyzed") and "performance" in result:
                performance = result["performance"]
                glyph_analysis = result.get("glyph_analysis", {})
                
                # Fixed: Use dict access instead of getattr (o3's issues #3 and #4)
                training_results[condition] = {
                    "final_glyph_loss": performance.get("final_glyph_loss", 0.0) if isinstance(performance, dict) else getattr(performance, "final_glyph_loss", 0.0),
                    "final_silence_loss": performance.get("final_silence_loss", 0.0) if isinstance(performance, dict) else getattr(performance, "final_silence_loss", 0.0),
                    "silence_ratio": glyph_analysis.get("silence_ratio", 0.0),
                    "glyph_improvement_percent": 0.0  # Would need training curves to calculate
                }
                
                if "behavioral_profile" in result:
                    behavioral = result["behavioral_profile"]
                    model_behaviors[condition] = {
                        "stress_response": behavioral.get("crisis_management_style", "unknown") if isinstance(behavioral, dict) else getattr(behavioral, "crisis_management_style", "unknown"),
                        "adaptation_strategy": behavioral.get("adaptation_strategy", "unknown") if isinstance(behavioral, dict) else getattr(behavioral, "adaptation_strategy", "unknown")
                    }
        
        if training_results:
            # Conduct philosophical analysis
            insights = philosophical.analyze_training_philosophy(training_results, model_behaviors)
            epistemological = philosophical.generate_epistemological_analysis(training_results)
            philosophical_report = philosophical.generate_contemplative_report()
            
            # Save philosophical report
            philosophical_path = f"results/reports/controlled_comparison_philosophy_{timestamp}.txt"
            with open(philosophical_path, 'w', encoding='utf-8') as f:
                f.write("üßò CONTROLLED COMPARISON - PHILOSOPHICAL IMPLICATIONS\n")
                f.write("=" * 80 + "\n")
                f.write(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("üéØ 2√ó2 EXPERIMENTAL DESIGN PHILOSOPHICAL ANALYSIS\n\n")
                f.write(philosophical_report)
                
                f.write("\n\nüî¨ PARADIGM √ó STRESS INTERACTION ANALYSIS:\n")
                f.write("=" * 50 + "\n")
                f.write("The 2√ó2 design allows us to separate:\n")
                f.write("‚Ä¢ PARADIGM EFFECTS: Ecological vs Abstract learning approaches\n")
                f.write("‚Ä¢ STRESS EFFECTS: Calm vs Chaotic environmental conditions\n")
                f.write("‚Ä¢ INTERACTION EFFECTS: How paradigms respond differently to stress\n\n")
                
                if len(training_results) >= 4:
                    f.write("This reveals the deep wisdom of contemplative AI:\n")
                    f.write("Each paradigm-stress combination teaches unique lessons about\n")
                    f.write("the nature of intelligence, adaptation, and silence.\n")
            
            print(f"   üìÅ Saved to: {philosophical_path}")
        
        # 3. Summary Report
        print("üìã Generating executive summary...")
        summary_path = f"results/reports/controlled_comparison_summary_{timestamp}.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("üìä CONTROLLED COMPARISON EXPERIMENT - EXECUTIVE SUMMARY\n")
            f.write("=" * 70 + "\n")
            f.write(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("üéØ EXPERIMENTAL DESIGN:\n")
            f.write("2√ó2 factorial design separating paradigm effects from stress effects\n\n")
            
            f.write("üìä MODELS ANALYZED:\n")
            for condition, result in results.items():
                status = "‚úÖ SUCCESS" if result.get("analyzed") else "‚ùå FAILED"
                f.write(f"   {condition}: {status}\n")
                if result.get("model_path"):
                    model_size = get_file_size_kb(result["model_path"])
                    f.write(f"      Model: {result['model_path']} ({model_size})\n")
            
            f.write(f"\nüìÅ DETAILED REPORTS:\n")
            f.write(f"   üî¨ Technical Analysis: {report_path}\n")
            if 'philosophical_path' in locals():
                f.write(f"   üßò Philosophical Analysis: {philosophical_path}\n")
            f.write(f"   üìã This Summary: {summary_path}\n")
            
            f.write(f"\nüå± NEXT STEPS:\n")
            f.write(f"   1. Review detailed analysis reports\n")
            f.write(f"   2. Compare paradigm effectiveness under different stress conditions\n")
            f.write(f"   3. Analyze interaction effects between paradigm and environment\n")
            f.write(f"   4. Consider implications for contemplative AI development\n")
        
        print(f"   üìÅ Saved to: {summary_path}")
        
        print(f"\nüéâ COMPREHENSIVE ANALYSIS COMPLETE!")
        print(f"üìÇ Three detailed reports generated with timestamp {timestamp}")
        print(f"   üìä Analysis: results/analysis/")
        print(f"   üìã Reports: results/reports/")
        print(f"   üìà Statistics: results/statistical_analysis/")
        
    except Exception as e:
        print(f"‚ùå Error generating reports: {e}")
        import traceback
        traceback.print_exc()
    
    return results

def main():
    """Run the complete controlled comparison experiment"""
    
    # Fixed: Add --no-prompt CLI option (o3's issue #7)
    parser = argparse.ArgumentParser(description="Controlled Spiramycel Comparison Experiment")
    parser.add_argument("--no-prompt", action="store_true", 
                       help="Skip interactive prompts (useful for automation)")
    args = parser.parse_args()
    
    # Setup experiment logging
    main_log_file, timestamp = setup_experiment_logging()
    main_logger = logging.getLogger()
    
    print("üß™ CONTROLLED SPIRAMYCEL COMPARISON EXPERIMENT")
    print("=" * 70)
    print("üéØ Goal: Separate paradigm effects from stress effects")
    print("üìä Design: 2x2 (Ecological/Abstract √ó Calm/Chaotic)")
    print("‚è∞ Expected duration: 30-60 minutes total")
    print("")
    print("üìã DOCUMENTATION GENERATED:")
    print("   üî¨ Technical comparative analysis report")
    print("   üßò Philosophical implications analysis")
    print("   üìä Executive summary with next steps")
    print("   üìÇ All reports timestamped and preserved")
    print(f"   üìù Main experiment log: {main_log_file}")
    print("   üìÅ Individual condition logs in logs/ directory")
    
    # Log experiment start
    main_logger.info("üß™ CONTROLLED SPIRAMYCEL COMPARISON EXPERIMENT STARTED")
    main_logger.info(f"Timestamp: {timestamp}")
    main_logger.info(f"Args: no_prompt={args.no_prompt}")
    
    # Fixed: Skip prompt if requested or not a TTY (o3's issue #7)
    if not args.no_prompt and sys.stdin.isatty():
        try:
            input("\nPress Enter to start the experiment (Ctrl+C to abort)...")
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è Experiment aborted by user")
            main_logger.info("Experiment aborted by user")
            return
    else:
        print("\nüöÄ Starting experiment automatically...")
        main_logger.info("Starting experiment automatically")
    
    start_time = time.time()
    trained_models = {}
    
    try:
        # Run all four conditions with individual loggers
        print("\nüöÄ PHASE 1: Training all four conditions...")
        main_logger.info("PHASE 1: Training all four conditions")
        
        # 1. Ecological Calm (A)
        print(f"\nüå± Training condition A: Ecological + Calm")
        eco_calm_logger, eco_calm_log = create_condition_logger("ecological_calm", timestamp)
        main_logger.info(f"Starting Ecological Calm training - log: {eco_calm_log}")
        
        model_a = run_ecological_training(chaos_mode=False, suffix="calm", no_prompt=args.no_prompt,
                                        condition_logger=eco_calm_logger, timestamp=timestamp)
        trained_models["ecological_calm"] = model_a
        main_logger.info(f"Ecological Calm completed: {model_a}")
        
        # 2. Ecological Chaotic (B) 
        print(f"\nüåã Training condition B: Ecological + Chaotic")
        eco_chaos_logger, eco_chaos_log = create_condition_logger("ecological_chaotic", timestamp)
        main_logger.info(f"Starting Ecological Chaotic training - log: {eco_chaos_log}")
        
        model_b = run_ecological_training(chaos_mode=True, suffix="chaotic", no_prompt=args.no_prompt,
                                        condition_logger=eco_chaos_logger, timestamp=timestamp)
        trained_models["ecological_chaotic"] = model_b
        main_logger.info(f"Ecological Chaotic completed: {model_b}")
        
        # 3. Abstract Calm (C)
        print(f"\nüßò Training condition C: Abstract + Calm")  
        abs_calm_logger, abs_calm_log = create_condition_logger("abstract_calm", timestamp)
        main_logger.info(f"Starting Abstract Calm training - log: {abs_calm_log}")
        
        model_c = run_abstract_training(chaos_mode=False, suffix="calm", no_prompt=args.no_prompt,
                                      condition_logger=abs_calm_logger, timestamp=timestamp)
        trained_models["abstract_calm"] = model_c
        main_logger.info(f"Abstract Calm completed: {model_c}")
        
        # 4. Abstract Chaotic (D)
        print(f"\n‚ö° Training condition D: Abstract + Chaotic")
        abs_chaos_logger, abs_chaos_log = create_condition_logger("abstract_chaotic", timestamp)
        main_logger.info(f"Starting Abstract Chaotic training - log: {abs_chaos_log}")
        
        model_d = run_abstract_training(chaos_mode=True, suffix="chaotic", no_prompt=args.no_prompt,
                                      condition_logger=abs_chaos_logger, timestamp=timestamp)
        trained_models["abstract_chaotic"] = model_d
        main_logger.info(f"Abstract Chaotic completed: {model_d}")
        
        training_time = time.time() - start_time
        print(f"\n‚úÖ All training complete in {training_time/60:.1f} minutes!")
        main_logger.info(f"All training complete in {training_time/60:.1f} minutes")
        
        # Log all created log files
        print(f"\nüìù INDIVIDUAL CONDITION LOGS CREATED:")
        print(f"   üå± Ecological Calm: {eco_calm_log}")
        print(f"   üåã Ecological Chaotic: {eco_chaos_log}")  
        print(f"   üßò Abstract Calm: {abs_calm_log}")
        print(f"   ‚ö° Abstract Chaotic: {abs_chaos_log}")
        
        # PHASE 2: Comprehensive Analysis (now much more powerful!)
        print(f"\nüî¨ PHASE 2: Comprehensive Analysis")
        print("This will analyze:")
        print("   ‚Ä¢ Glyph usage patterns and contemplative ratios")
        print("   ‚Ä¢ Behavioral profiles under different stress conditions") 
        print("   ‚Ä¢ Philosophical implications of paradigm differences")
        print("   ‚Ä¢ Epistemological analysis of learning approaches")
        print("   ‚Ä¢ Interaction effects between paradigm and environment")
        
        main_logger.info("PHASE 2: Starting comprehensive analysis")
        results = run_comparative_analysis(trained_models)
        main_logger.info("Comprehensive analysis completed")
        
        # PHASE 3: Results Summary
        print(f"\nüìã EXPERIMENTAL RESULTS SUMMARY")
        print("=" * 60)
        
        print(f"\nüìä 2√ó2 DESIGN RESULTS:")
        print(f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
        print(f"‚îÇ             ‚îÇ   CALM       ‚îÇ   CHAOTIC    ‚îÇ")
        print(f"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
        
        eco_calm = "‚úÖ" if results.get("ecological_calm", {}).get("analyzed") else "‚ùå"
        eco_chaos = "‚úÖ" if results.get("ecological_chaotic", {}).get("analyzed") else "‚ùå"
        abs_calm = "‚úÖ" if results.get("abstract_calm", {}).get("analyzed") else "‚ùå" 
        abs_chaos = "‚úÖ" if results.get("abstract_chaotic", {}).get("analyzed") else "‚ùå"
        
        print(f"‚îÇ ECOLOGICAL  ‚îÇ   {eco_calm} (A)     ‚îÇ   {eco_chaos} (B)     ‚îÇ")
        print(f"‚îÇ ABSTRACT    ‚îÇ   {abs_calm} (C)     ‚îÇ   {abs_chaos} (D)     ‚îÇ")
        print(f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
        
        print(f"\nüéØ ANALYSIS IMPLICATIONS:")
        print(f"   ‚Ä¢ A vs C: Paradigm effect under calm conditions")
        print(f"   ‚Ä¢ B vs D: Paradigm effect under chaotic conditions") 
        print(f"   ‚Ä¢ A vs B: Stress effect for ecological paradigm")
        print(f"   ‚Ä¢ C vs D: Stress effect for abstract paradigm")
        
        print(f"\nüìÅ Models saved for detailed analysis:")
        for condition, model_path in trained_models.items():
            if model_path:
                model_size = get_file_size_kb(model_path)
                print(f"   {condition}: {model_path} ({model_size})")
        
        print(f"\nüìÇ Model Organization:")
        print(f"   üìÅ ecological_models/")
        eco_calm_size = get_file_size_kb(trained_models.get("ecological_calm", "")) if trained_models.get("ecological_calm") else "N/A"
        eco_chaos_size = get_file_size_kb(trained_models.get("ecological_chaotic", "")) if trained_models.get("ecological_chaotic") else "N/A"
        print(f"      ‚îî‚îÄ‚îÄ ecological_calm_model.pt ({eco_calm_size})")
        print(f"      ‚îî‚îÄ‚îÄ ecological_chaotic_model.pt ({eco_chaos_size})")
        print(f"   üìÅ abstract_models/")
        abs_calm_size = get_file_size_kb(trained_models.get("abstract_calm", "")) if trained_models.get("abstract_calm") else "N/A"
        abs_chaos_size = get_file_size_kb(trained_models.get("abstract_chaotic", "")) if trained_models.get("abstract_chaotic") else "N/A"
        print(f"      ‚îî‚îÄ‚îÄ abstract_calm_model.pt ({abs_calm_size})")
        print(f"      ‚îî‚îÄ‚îÄ abstract_chaotic_model.pt ({abs_chaos_size})")
        
        total_time = time.time() - start_time
        print(f"\nüéâ Experiment complete in {total_time/60:.1f} minutes!")
        print(f"üî¨ Ready for detailed contemplative analysis!")
        print(f"üå± All four oscillatory femto language models preserved!")
        print(f"üìã Check the comprehensive analysis reports for deep insights!")
        print(f"\nüìù COMPLETE LOGGING DOCUMENTATION:")
        print(f"   üìñ Main experiment log: {main_log_file}")
        print(f"   üìÅ Individual condition logs in logs/ directory")
        print(f"   üìä All training details, glyph patterns, and metrics captured!")
        
        main_logger.info(f"EXPERIMENT COMPLETED SUCCESSFULLY in {total_time/60:.1f} minutes")
        main_logger.info("All models trained, analyzed, and documented")
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Experiment interrupted by user")
        elapsed = (time.time() - start_time) / 60
        print(f"   Partial completion time: {elapsed:.1f} minutes")
        print(f"   Check saved models in ecological_models/ and abstract_models/")
        main_logger.info(f"Experiment interrupted by user after {elapsed:.1f} minutes")
    
    except Exception as e:
        print(f"\n‚ùå Experiment failed: {e}")
        print(f"   Check individual training components")
        main_logger.error(f"Experiment failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 